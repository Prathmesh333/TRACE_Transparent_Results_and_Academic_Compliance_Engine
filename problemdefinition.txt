üèóÔ∏è Opti-Scholar: Micro-Component Architecture
üß© Layer 1: The Ingestion & Identity Layer (The Foundation)
Before any AI happens, we must ensure data integrity and identity.

1. Secure Document Gateway (API Endpoint)

Function: Accepts uploads (PDF/JPG) from teachers and validates file types/size.
Tech: FastAPI + Python-Multipart.
Output: A unique batch_id for tracking.
2. Vision-Based ID Extractor (Computer Vision)

Function: Scans the header of uploaded exams to find Student Registration Numbers.
Tech: OpenCV (Contour Detection) or Tesseract OCR.
Output: Links the answer sheet to a specific student_id in the database.
3. Rubric Parser (GenAI Pre-processor)

Function: Takes a teacher's messy text rubric (e.g., "Give 5 points if they mention Newton's law") and structures it into a JSON schema for the AI.
Tech: GPT-4o-mini (Structured Output).
Output: Standardized grading_schema.json.
üß© Layer 2: Automated Grading & Assessment (Scope 1)
Breaking down the grading process into granular steps.

4. Context-Aware Semantic Scorer (GenAI Core)

Function: Reads the student's answer and the grading_schema. Assigns points based on logic, not just keyword matching.
Tech: OpenAI API (System Prompting).
Innovation: Can handle "partial credit" logic (e.g., "Formula is correct, calculation error -1 point").
5. Confidence Quantifier (Traditional AI)

Function: Assigns a probability score (0.0 to 1.0) to the AI's grading decision.
Tech: Softmax layer output or token probability analysis.
Logic: If confidence < 0.7, the exam is flagged for "Manual Human Review" automatically.
6. Qualitative Feedback Generator (GenAI)

Function: Converts the numerical score into a helpful paragraph.
Tech: LLM summarization.
Input: "Score: 7/10. Rubric: Missed conclusion."
Output: "You demonstrated great understanding of the concepts, but ensure you finish with a strong conclusion to secure full marks."
üß© Layer 3: Grade Accuracy & Verification (Scope 2)
The "Quality Control" pipeline using statistical math.

7. Temporal Anomaly Detector (Unsupervised Learning)

Function: Compares a student's current grade against their personal moving average (last 5 exams).
Tech: Z-Score Analysis (
z=(x‚àíŒº)/œÉ
).
Trigger: Flags if score deviates by > 2.5 standard deviations.
8. Class Distribution Balancer (Descriptive Statistics)

Function: Detects "Grade Inflation" or "Harsh Grading" by the teacher.
Tech: Kurtosis and Skewness calculation.
Trigger: Alerts Admin if Class Skewness > 1.0 (too many high grades) or < -1.0 (too many low grades).
9. Cross-Model Consistency Checker (Hybrid AI)

Function: Runs the same answer through two different models (e.g., GPT-4o and Claude 3).
Tech: Diff Algorithm.
Logic: If Grade(Model A) != Grade(Model B), flag for conflict resolution.
üß© Layer 4: Attendance & Predictive Risk (Scope 3)
Moving from simple tracking to predictive analytics.

10. Pattern Miner (Sequential Pattern Mining)

Function: Identifies specific habits. E.g., "Student X always misses the class after a long weekend."
Tech: PrefixSpan Algorithm or Apriori.
Output: Categorized absence patterns.
11. Subject-Correlation Engine (Statistical Analysis)

Function: Calculates Pearson Correlation Coefficient (
r
) between Attendance % and Final Grade for each specific subject.
Tech: Pandas/Scipy pearsonr.
Insight: "Math Grade has 
r=0.9
 with attendance (Critical), but Art has 
r=0.2
 (Flexible)."
12. Dropout Risk Classifier (Supervised Learning)

Function: Predicts probability of failing the semester.
Tech: Logistic Regression (Features: Current Attendance, Current Grade, Attendance Trend).
Output: risk_score (Low, Medium, High).
üß© Layer 5: Integrated Management (Scope 4)
The interface, communication, and feedback loops.

13. Vector-Store Resource Recommender (RAG)

Function: If a student fails a specific topic, finds the exact PDF/Video link to help them.
Tech: OpenAI Embeddings (text-embedding-3-small) + FAISS Vector DB.
Logic: Query vector for "Failed Topic: Thermodynamics" 
‚Üí
 Retrieve relevant study materials.
14. Sentiment-Driven Ticket Router (NLP)

Function: Handles student complaints/feedback.
Tech: VADER (Valence Aware Dictionary and sEntiment Reasoner) or RoBERTa.
Logic:
Negative + Urgent 
‚Üí
 Route to Admin Priority Queue.
Neutral + Academic 
‚Üí
 Route to Teacher Query Queue.
15. Explainable AI (XAI) Visualizer

Function: Shows the student why they got a grade.
Tech: SHAP (SHapley Additive exPlanations) values or simple Attention Highlighting.
Visual: Highlights the specific sentence in the student's essay that caused the grade deduction.
üìä The Micro-Service Data Flow (Demo Narrative)
When you present this, you don't list features; you trace the Lifecycle of a Data Point:

Ingestion: "The exam enters via the Secure Gateway. The ID Extractor identifies it as Student #404."
Processing: "The Rubric Parser converts the teacher's rules into JSON. The Semantic Scorer evaluates the answer."
Verification: "Simultaneously, the Confidence Quantifier ensures the AI is sure. Meanwhile, the Temporal Anomaly Detector checks: Is this score normal for Student #404? Yes? Proceed."
Analysis: "Data flows to the Subject-Correlation Engine. We see Student #404 has missed 3 Math classes. Since Math has a 0.9 correlation with attendance, the Risk Classifier flags them as 'High Risk'."
Action: "The Resource Recommender finds a Math remedial video. The system sends an email using the Feedback Generator."
üõ†Ô∏è Refined Tech Stack (Component Specific)
Micro-Component
Library/Tool
Purpose
ID Extractor	pytesseract / opencv-python	OCR & Image Processing
Semantic Scorer	openai (GPT-4o)	Logic & Understanding
Anomaly Detector	scikit-learn (IsolationForest)	Outlier Detection
Risk Classifier	scikit-learn (LogisticRegression)	Prediction
Resource Recommender	faiss-cpu / chromadb	Vector Search
Sentiment Router	nltk (VADER)	Text Analysis
API Layer	fastapi	High-performance backend
Dashboard	streamlit-aggrid	Interactive Data Grids

üöÄ Why "Micro-Components" Wins
Debuggability: If grading fails, you know it's the Semantic Scorer, not just "The AI."
Scalability: You can swap the Semantic Scorer from GPT-4 to Claude 3 without breaking the Risk Classifier.
Modularity: You can demonstrate the Attendance Pattern Miner as a standalone cool feature if the grading API is down during the demo.
This level of granularity turns a "project" into a "system."